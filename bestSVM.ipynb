{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm as svm_sk\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "import time\n",
    "\n",
    "# Preprocessing Training data\n",
    "fruit_images_t = []\n",
    "labels_t = []\n",
    "imagesize = 45\n",
    "for fruit_dir_path in glob.glob(\"fruits-360/Training/*\"):\n",
    "    fruit_label = fruit_dir_path.split(\"\\\\\")[-1]\n",
    "    for image_path in glob.glob(os.path.join(fruit_dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        image = cv2.resize(image, (imagesize, imagesize))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        fruit_images_t.append(image)\n",
    "        labels_t.append(fruit_label)\n",
    "fruit_images_t = np.array(fruit_images_t)\n",
    "labels_t = np.array(labels_t)\n",
    "\n",
    "# Preprocessing Validation data\n",
    "fruit_images_v = []\n",
    "labels_v = []\n",
    "for fruit_dir_path in glob.glob(\"fruits-360/Validation/*\"):\n",
    "    fruit_label = fruit_dir_path.split(\"\\\\\")[-1]\n",
    "    for image_path in glob.glob(os.path.join(fruit_dir_path, \"*.jpg\")):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        image = cv2.resize(image, (imagesize, imagesize))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        fruit_images_v.append(image)\n",
    "        labels_v.append(fruit_label)\n",
    "fruit_images_v = np.array(fruit_images_v)\n",
    "labels_v = np.array(labels_v)\n",
    "\n",
    "# Create dicts/arrays for Training Data\n",
    "names_t = np.unique(labels_t)\n",
    "ids_t = [k for k in range(0, len(names_t))]\n",
    "name_id_t = list(zip(names_t, ids_t))\n",
    "id_to_name_t = {id: name for (name, id) in name_id_t}\n",
    "name_to_id_t = {name: id for (name, id) in name_id_t}\n",
    "label_ids_t = np.array([name_to_id_t[x] for x in labels_t])\n",
    "\n",
    "# Create dicts/arrays for Validation data\n",
    "names_v = np.unique(labels_v)\n",
    "ids_v = [k for k in range(len(names_v))]\n",
    "id_name_v = list(zip(ids_v, names_v))\n",
    "name_to_id_v = {name: id for (id, name) in id_name_v}\n",
    "id_to_name_v = {id: name for (id, name) in id_name_v}\n",
    "label_ids_v = np.array([name_to_id_v[x] for x in labels_v])\n",
    "\n",
    "#End of preprocessing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28736, 24)\n",
      "[0.9680554119714669]\n"
     ]
    }
   ],
   "source": [
    "# Test number of PCA components... \n",
    "# Scale Training data and then run PCA on it\n",
    "st = 24\n",
    "nd = 24\n",
    "accuracys = []\n",
    "times = []\n",
    "scaler = StandardScaler()\n",
    "scaled_images = scaler.fit_transform([im.flatten() for im in fruit_images_t])\n",
    "images_scaled = scaler.transform([im.flatten() for im in fruit_images_v])\n",
    "count = 1\n",
    "pca = PCA(n_components=nd)\n",
    "pca_result_t = pca.fit_transform(scaled_images)\n",
    "pca_result_v = pca.transform(images_scaled)\n",
    "print(pca_result_t.shape)\n",
    "for i in range(st, nd + 1):\n",
    "    tst = time.time()\n",
    "    acc = 0    \n",
    "    for j in range(count):      \n",
    "        # Split training set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(pca_result_t[:,:i], label_ids_t, test_size=0)\n",
    "        # Train svm\n",
    "        svm = svm_sk.SVC(C=1.0, kernel='poly', degree=1)\n",
    "        svm = svm.fit(X_train, y_train)\n",
    "        # Predict on with all classifiers Validation data\n",
    "        svm_prediction_v = svm.predict(pca_result_v[:,:i])\n",
    "        # Compute accuracy scores for all classifiers\n",
    "        svm_precision_v = accuracy_score(svm_prediction_v, label_ids_v)\n",
    "        acc += svm_precision_v/count\n",
    "    accuracys.append(acc)\n",
    "    times.append(time.time()-tst)\n",
    "    #print(i)\n",
    "print(accuracys)\n",
    "#plt.bar(np.linspace(st,nd,nd+1-st), times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
